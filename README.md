# NewsRAG

This repository follows the development of a personal project focused on the study of **Python applied to Data and Artificial Intelligence**, with a focus on **data collection, data quality, and NLP/RAG applications**.

The idea of the project is to build, step by step, a pipeline capable of:
- Automatically collecting news articles
- Evaluating the quality of the collected data
- Preparing this data for use in language models
- Allowing, in the future, chatbot interaction based on the ingested content

The project is under continuous evolution and documents both technical decisions and learnings throughout the process.

---

## ğŸ¯ Project Objective

- Automatically collect news (initially via RSS).
- Respect scraping best practices (robots.txt, rate limit).
- Store data in a structured format (JSON).
- Measure **ingestion quality** through objective metrics.
- Prepare data for future stages:
  - Processing and cleaning
  - Semantic evaluation
  - Retrieval-Augmented Generation (RAG)

---

## ğŸ› ï¸ Technologies Used (so far)

- **Python 3.11**
- **feedparser** â€” RSS feed parsing
- **trafilatura** â€” download and text extraction
- **Conda** â€” environment management
- **Git/GitHub** â€” versioning and project documentation

---

## ğŸ“Œ Current Project Status

âœ” Initial ingestion pipeline implemented  
âœ” News collection via RSS  
âœ” Access verification via `robots.txt`  
âœ” Text extraction from pages  
âœ” Structured saving in JSON  
âœ” Generation of ingestion quality metrics:
  - failed downloads
  - robots.txt blocks
  - empty extractions
  - fallback usage
  - text length statistics

âœ” Execution reports saved in JSON for auditing and future comparison  

---

## ğŸ“Š Current Structure
NewsRAG/
â”œâ”€ data/
â”‚  â””â”€ raw/           # Raw collected data
â”œâ”€ scripts/
â”‚  â”œâ”€ data_ingest.py
â”‚  â””â”€ utils.py
â”œâ”€ reports/          # Generated ingestion reports
â”œâ”€ environment.yml
â”œâ”€ README.md
â””â”€ .gitignore


---

## ğŸš€ Next Steps

- Processing and cleaning of collected texts
- Definition of simple semantic quality criteria
- Text chunking
- Embedding generation
- Initial structuring of a RAG pipeline
- Exploration via notebooks

---

## âš™ï¸ How to Run (current)

> Instructions will be refined as the project evolves.

1. Create the Conda environment:
Bash

conda env create -f environment.yml
conda activate newsrag-env

2. Run the ingestion script:
Bash

python scripts/data_ingest.py


### ğŸ‘¨â€ğŸ’» About Me
I am a Systems Analysis and Development student, focusing on Data and Artificial Intelligence. This project is a personal initiative to apply theoretical concepts, learn industry tools (Python, Git, data pipelines), and document my learning process in a practical and transparent way.